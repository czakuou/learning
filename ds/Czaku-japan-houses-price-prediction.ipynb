{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom os import listdir\nfrom os.path import isfile, join\nimport numpy as np\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import train_test_split \nfrom sklearn import metrics \nfrom sklearn.preprocessing import OneHotEncoder\nimport sklearn\nimport gc\nimport sys\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression,SGDRegressor\nbase_path = '/kaggle/input/japan-real-estate-transaction-prices/'\nfrom copy import deepcopy as d\nfrom sklearn.metrics import r2_score\nimport itertools\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-28T14:06:16.634846Z","iopub.execute_input":"2021-09-28T14:06:16.635190Z","iopub.status.idle":"2021-09-28T14:06:16.642333Z","shell.execute_reply.started":"2021-09-28T14:06:16.635158Z","shell.execute_reply":"2021-09-28T14:06:16.641735Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def get_dataset(dataset_path: str, codes_path: str) -> pd.DataFrame:\n    \n    only_files = (join(dataset_path, f) for f in listdir(dataset_path) if isfile(join(dataset_path, f)))\n\n    ### Połącz listę DataFrame'ów w jeden główny DataFrame    \n    main_df = pd.concat((pd.read_csv(f, low_memory=False) for f in only_files))\n    ###\n    \n    codes = pd.read_csv(codes_path)\n    \n    ### Usuń kolumnę JpName z DataFrameu codes\n    codes = codes.drop(columns=['JpName'])\n    ###\n    \n    ### Zmień nazwę kolumny Quarter na Code\n    main_df = main_df.rename(columns={\"Quarter\": \"Code\"})\n    ###\n    \n    main_df = main_df.join(codes, on='Code', rsuffix=\"_pref\")\n    \n    return main_df","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:06:16.643695Z","iopub.execute_input":"2021-09-28T14:06:16.644373Z","iopub.status.idle":"2021-09-28T14:06:16.660194Z","shell.execute_reply.started":"2021-09-28T14:06:16.644328Z","shell.execute_reply":"2021-09-28T14:06:16.659444Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def data_preprocessing(df: pd.DataFrame, target: str, columns_to_drop: list) -> (pd.DataFrame, pd.DataFrame, list, list):\n    \n    df = df.drop(columns=columns_to_drop)\n    target='TradePrice'\n    df = df.dropna(subset=[target])\n    \n    categorical_columns = df.select_dtypes(include=[np.object]).columns.tolist()\n    numerical_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n    \n    df_cat = df[categorical_columns]\n    df_cat = df_cat.fillna(\"Unknown\")\n    \n    ### Dokonaj woboru kolumn numerycznych DataFrame'u \"df\" do zmiennej df_num\n    df_num = df[numerical_columns]\n    \n    ### Wypełnij brakujące wartości DataFrame'u df_num średnią poszczególnych kolumn (funkcjia mean())\n    df_num = df_num.fillna(df_num.mean())\n    ###\n    \n    return df_cat, df_num, categorical_columns, numerical_columns\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:06:16.661334Z","iopub.execute_input":"2021-09-28T14:06:16.661724Z","iopub.status.idle":"2021-09-28T14:06:16.677476Z","shell.execute_reply.started":"2021-09-28T14:06:16.661682Z","shell.execute_reply":"2021-09-28T14:06:16.676808Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def get_encoder(df: pd.DataFrame, target: str, columns_to_drop: list) -> (pd.DataFrame, sklearn.preprocessing.OneHotEncoder):\n    \n    enc = OneHotEncoder(handle_unknown='error', drop='first')\n    scaler = StandardScaler()\n    \n    ### Użyj poprzednio napisanej funkcji (data_preprocessing) by przetworzyć dane w sposób nadający się do enkodingu\n    df_cat, df_num, categorical_columns, numerical_columns = data_preprocessing(df, target, columns_to_drop)\n    ###\n    \n    enc.fit(df_cat)\n    scaler.fit(df_num)\n    \n    df = df_cat\n    \n    for column in df_num.columns:\n        df[column] = df_num[column]\n    \n    return df, enc, scaler, categorical_columns, numerical_columns","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:06:16.679168Z","iopub.execute_input":"2021-09-28T14:06:16.679401Z","iopub.status.idle":"2021-09-28T14:06:16.701865Z","shell.execute_reply.started":"2021-09-28T14:06:16.679376Z","shell.execute_reply":"2021-09-28T14:06:16.700591Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def transform_df_to_arrays(df: pd.DataFrame, categorical_columns: list, numerical_columns: list,target: str, scaler: sklearn.preprocessing.StandardScaler, enc: sklearn.preprocessing.OneHotEncoder ) -> (np.array, np.array):\n    \n    categorical_array  = enc.transform(df[categorical_columns]).toarray()\n    df[numerical_columns] = scaler.transform(df[numerical_columns])\n    \n    numerical_array = df.drop(columns = [target] + categorical_columns).values\n    join_columns = d(numerical_columns)\n    join_columns.remove(target)\n    \n    ### Połącz macierz z danymi numerycznymi z macierzą z zaenkodowanymi zmiennymi kategorialnymi \n    X = np.concatenate([categorical_array, numerical_array], axis=1)\n    ###\n    y = df[target].values\n    \n    return X, y\n\ndef get_generator(df: pd.DataFrame, categorical_columns: list, numerical_columns: list, target: str, scaler: sklearn.preprocessing.StandardScaler, enc: sklearn.preprocessing.OneHotEncoder, number_of_splits: int =32) -> (np.array,np.array):\n    \n    number_of_splits = number_of_splits    \n    \n    for chunk in itertools.cycle(np.array_split(df, number_of_splits)):\n        ### Użyj poprzednio napisanej funkcji (transform_df_to_arrays) by przetworzyć wybrany kawałek danych \n        X, y = transform_df_to_arrays(chunk, categorical_columns, numerical_columns, target, scaler, enc)\n        ### \n        yield X, y\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:06:16.703399Z","iopub.execute_input":"2021-09-28T14:06:16.703761Z","iopub.status.idle":"2021-09-28T14:06:16.719125Z","shell.execute_reply.started":"2021-09-28T14:06:16.703723Z","shell.execute_reply":"2021-09-28T14:06:16.717796Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def train(dataset_path: str,codes_path: str,number_of_splits: int,test_size: float) -> np.array:\n    \n    print('[INFO] Loading dataset...')\n    \n    df = get_dataset(dataset_path, codes_path)\n    \n    print(\"[INFO] Dataset has been loaded...\")\n    \n    columns_to_drop = 'UnitPrice PricePerTsubo TotalFloorArea Remarks TimeToNearestStation DistrictName NearestStation'.split()\n    \n    df, enc, scaler, categorical_columns, numerical_columns = get_encoder(df=df,target='TradePrice',columns_to_drop=columns_to_drop)\n    \n    print(\"[INFO] Encoder has been created...\")\n    target = 'TradePrice'\n    \n    ### Rozdziel zbiór danych an zbiór traningowy i testowy\n    df_train, df_test = train_test_split(df, test_size=test_size, random_state=42) \n    ###\n    \n    print(\"[INFO] Data has been split...\")\n    \n    test_generator = get_generator(df_test,categorical_columns, numerical_columns,target, scaler,enc,number_of_splits=int(number_of_splits * test_size))\n    train_generator = get_generator(df_train,categorical_columns, numerical_columns,target, scaler,enc,number_of_splits=int(number_of_splits * (1-test_size)))\n    \n    del df\n    gc.collect()\n\n    print(\"[INFO] Generator has been created...\")\n    print(\"[INFO] Starting training...\")\n    reg = SGDRegressor()\n        \n    for _ in range(int(number_of_splits*(1-test_size))):\n        ### Dla każdej iteracji pętli wydobądź następny batch z generatora treningowego\n        X, y  = next(train_generator)\n        ###\n        reg.partial_fit(X, y)\n            \n    r2_scores = []\n\n\n    for _ in range(int(number_of_splits*(test_size))):\n        ### Dla każdej iteracji pętli wydobądź następny batch z generatora testowego\n        X, y  = next(test_generator)\n        ###\n        res = reg.predict(X)\n        ### Do listy r2_scores dodaj współczynnik determinacji r^2 dla przewidzianej wartość i rzeczywistej wartości przy użyciu funkcji r2_score\n        r2 = r2_score(y, res)\n        r2_scores.append(r2)\n        ###\n    \n    print(\"[INFO] Training has finished...\")\n    \n    return np.array(r2_scores), reg\n","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:06:16.720587Z","iopub.execute_input":"2021-09-28T14:06:16.721343Z","iopub.status.idle":"2021-09-28T14:06:16.742883Z","shell.execute_reply.started":"2021-09-28T14:06:16.721302Z","shell.execute_reply":"2021-09-28T14:06:16.741982Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"dataset_path = join(base_path, \"trade_prices\")\ncodes_path = join(base_path, \"prefecture_code.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:06:16.893425Z","iopub.execute_input":"2021-09-28T14:06:16.894105Z","iopub.status.idle":"2021-09-28T14:06:16.899215Z","shell.execute_reply.started":"2021-09-28T14:06:16.894066Z","shell.execute_reply":"2021-09-28T14:06:16.898361Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"scores, model = train(dataset_path, codes_path, number_of_splits=3000, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:06:16.915663Z","iopub.execute_input":"2021-09-28T14:06:16.916358Z","iopub.status.idle":"2021-09-28T14:10:02.770653Z","shell.execute_reply.started":"2021-09-28T14:06:16.916325Z","shell.execute_reply":"2021-09-28T14:10:02.769786Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"scores.mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:10:30.326883Z","iopub.execute_input":"2021-09-28T14:10:30.327175Z","iopub.status.idle":"2021-09-28T14:10:30.333666Z","shell.execute_reply.started":"2021-09-28T14:10:30.327147Z","shell.execute_reply":"2021-09-28T14:10:30.332928Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"plt.boxplot(scores)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:10:31.609981Z","iopub.execute_input":"2021-09-28T14:10:31.610725Z","iopub.status.idle":"2021-09-28T14:10:31.786811Z","shell.execute_reply.started":"2021-09-28T14:10:31.610682Z","shell.execute_reply":"2021-09-28T14:10:31.786159Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}